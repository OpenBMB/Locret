python auto_eval.py --pred_file /home/test/test01/hyx/LEval-main/Baselines/Predictions/exam_eval/Llama-3.1-8B-Instruct-lococo-2048/codeU.pred.jsonl
# python auto_eval.py --pred_file /home/test/test01/hyx/LEval-main/Baselines/Predictions/ngram_eval/Llama-3.1-8B-Instruct-lococo-2048/legal_contract_qa.pred.jsonl
# python auto_eval.py --pred_file /home/test/test01/hyx/LEval-main/Baselines/Predictions/ngram_eval/Llama-3.1-8B-Instruct-lococo-2048/meeting_summ.pred.jsonl
# python auto_eval.py --pred_file /home/test/test01/hyx/LEval-main/Baselines/Predictions/ngram_eval/Llama-3.1-8B-Instruct-lococo-2048/narrative_qa.pred.jsonl
# python auto_eval.py --pred_file /home/test/test01/hyx/LEval-main/Baselines/Predictions/ngram_eval/Llama-3.1-8B-Instruct-lococo-2048/natural_question.pred.jsonl
# python auto_eval.py --pred_file /home/test/test01/hyx/LEval-main/Baselines/Predictions/ngram_eval/Llama-3.1-8B-Instruct-lococo-2048/review_summ.pred.jsonl
