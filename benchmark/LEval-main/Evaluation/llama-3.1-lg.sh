# python auto_eval.py --pred_file /home/test/test01/hyx/LEval-main/Baselines/Predictions/exam_eval/Llama-3.1-8B-Instruct-lg-8192/codeU.pred.jsonl
# python auto_eval.py --pred_file /home/test/test01/hyx/LEval-main/Baselines/Predictions/exam_eval/Llama-3.1-8B-Instruct-lg-8192/sci_fi.pred.jsonl
# python auto_eval.py --pred_file /home/test/test01/hyx/LEval-main/Baselines/Predictions/ngram_eval/Llama-3.1-8B-Instruct-lg-8192/legal_contract_qa.pred.jsonl
# python auto_eval.py --pred_file /home/test/test01/hyx/LEval-main/Baselines/Predictions/ngram_eval/Llama-3.1-8B-Instruct-lg-8192/meeting_summ.pred.jsonl
python auto_eval.py --pred_file /home/test/test01/hyx/LEval-main/Baselines/Predictions/ngram_eval/Llama-3.1-8B-Instruct-lg-8192/narrative_qa.pred.jsonl
# python auto_eval.py --pred_file /home/test/test01/hyx/LEval-main/Baselines/Predictions/ngram_eval/Llama-3.1-8B-Instruct-lg-8192/natural_question.pred.jsonl
# python auto_eval.py --pred_file /home/test/test01/hyx/LEval-main/Baselines/Predictions/ngram_eval/Llama-3.1-8B-Instruct-lg-8192/review_summ.pred.jsonl
